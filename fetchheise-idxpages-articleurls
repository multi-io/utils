#!/usr/bin/env ruby
# in: URLs of one or more index pages on cmdline
# out: URLs of all articles referenced in those pages on stdout, one per line

require 'nokogiri'

ARGV.each do |url|
    page = Nokogiri::HTML(IO.popen("wget-withbrowsersettings -q -O- #{url}"))
    page.css('a').select{|a| a['class'] && a['class'].include?('posting_subject')}.each do |a|
        puts a['href']
    end
end

# TODO: optionally extract date/time and author name of each article
# TODO: generally, one would want to pipe sequences of real "article
#       records" with slots like "date", "author", "contents" (only
#       some of which may have to be filled) etc. between the
#       fetchheise-* processes instead of line-oriented URL lists
#
#       As a more limited solution, we could output the pieces of
#       article data on one line, separated by TAB characters. Or use
#       a page-oriented output (pages separated by \f)
